{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q -nc https://raw.githubusercontent.com/skyu0221/online-dropbox/master/ml/capstone2/poetry.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Input, Model, load_model\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_file(Config):\n",
    "    # 语料文本内容\n",
    "    files_content = ''\n",
    "    with open(Config.poetry_file, 'r',encoding='UTF-8') as f:\n",
    "        for line in f:\n",
    "            x = line.strip() + \"]\"\n",
    "            x = x.split(\":\")[1]\n",
    "            if len(x) <= 5 :\n",
    "                continue\n",
    "            if x[5] == '，':\n",
    "                files_content += x\n",
    "            \n",
    "\n",
    "    words = sorted(list(files_content))\n",
    "    counted_words = {}\n",
    "    for word in words:\n",
    "        if word in counted_words:\n",
    "            counted_words[word] += 1\n",
    "        else:\n",
    "            counted_words[word] = 1\n",
    "\n",
    "    # 去掉低频的字\n",
    "    erase = []\n",
    "    for key in counted_words:\n",
    "        if counted_words[key] <= 2:\n",
    "            erase.append(key)\n",
    "    for key in erase:\n",
    "        del counted_words[key]\n",
    "    wordPairs = sorted(counted_words.items(), key=lambda x: -x[1])\n",
    "\n",
    "    words, _ = zip(*wordPairs)\n",
    "    words += (\" \",)\n",
    "    # word到id的映射\n",
    "    word2num = dict((c, i) for i, c in enumerate(words))\n",
    "    num2word = dict((i, c) for i, c in enumerate(words))\n",
    "    word2numF = lambda x: word2num.get(x, len(words) - 1)\n",
    "    return word2numF, num2word, words, files_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoetryModel(object):\n",
    "    def __init__(self, config):\n",
    "        self.model = None\n",
    "        self.do_train = True\n",
    "        self.loaded_model = True\n",
    "        self.config = config\n",
    "\n",
    "        # 文件预处理\n",
    "        self.word2numF, self.num2word, self.words, self.files_content = preprocess_file(self.config)\n",
    "        \n",
    "        # 诗的list\n",
    "        self.poems = self.files_content.split(']')\n",
    "        # 诗的总数量\n",
    "        self.poems_num = len(self.poems)\n",
    "        \n",
    "        # 如果模型文件存在则直接加载模型，否则开始训练\n",
    "        if os.path.exists(self.config.weight_file) and self.loaded_model:\n",
    "            self.model = load_model(self.config.weight_file)\n",
    "        else:\n",
    "            self.train()\n",
    "\n",
    "    def build_model(self):\n",
    "        '''建立模型'''\n",
    "        print('building model')\n",
    "\n",
    "        # 输入的dimension\n",
    "        input_tensor = Input(shape=(self.config.max_len, len(self.words)))\n",
    "        lstm = LSTM(512, return_sequences=True)(input_tensor)\n",
    "        dropout = Dropout(0.6)(lstm)\n",
    "        lstm = LSTM(256)(dropout)\n",
    "        dropout = Dropout(0.6)(lstm)\n",
    "        dense = Dense(len(self.words), activation='softmax')(dropout)\n",
    "        self.model = Model(inputs=input_tensor, outputs=dense)\n",
    "        optimizer = Adam(lr=self.config.learning_rate)\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    def sample(self, preds, temperature=1.0):\n",
    "        '''\n",
    "        当temperature=1.0时，模型输出正常\n",
    "        当temperature=0.5时，模型输出比较open\n",
    "        当temperature=1.5时，模型输出比较保守\n",
    "        在训练的过程中可以看到temperature不同，结果也不同\n",
    "        就是一个概率分布变换的问题，保守的时候概率大的值变得更大，选择的可能性也更大\n",
    "        '''\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "        exp_preds = np.power(preds,1./temperature)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        pro = np.random.choice(range(len(preds)),1,p=preds)\n",
    "        return int(pro.squeeze())\n",
    "    \n",
    "    def generate_sample_result(self, epoch, logs):\n",
    "        '''训练过程中，每4个epoch打印出当前的学习情况'''\n",
    "        if epoch % 4 != 0:\n",
    "            return\n",
    "        \n",
    "        with open('out.txt', 'a',encoding='utf-8') as f:\n",
    "            f.write('==================Epoch {}=====================\\n'.format(epoch))\n",
    "                \n",
    "        print(\"\\n==================Epoch {}=====================\".format(epoch))\n",
    "        for diversity in [0.7, 1.0, 1.3]:\n",
    "            print(\"------------Diversity {}--------------\".format(diversity))\n",
    "            generate = self.predict_random(temperature=diversity)\n",
    "            print(generate)\n",
    "            \n",
    "            # 训练时的预测结果写入txt\n",
    "            with open('out.txt', 'a',encoding='utf-8') as f:\n",
    "                f.write(generate+'\\n')\n",
    "    \n",
    "    def predict_random(self,temperature = 1):\n",
    "        '''随机从库中选取一句开头的诗句，生成五言绝句'''\n",
    "        if not self.model:\n",
    "            print('model not loaded')\n",
    "            return\n",
    "        \n",
    "        index = random.randint(0, self.poems_num)\n",
    "        sentence = self.poems[index][: self.config.max_len]\n",
    "        generate = self.predict_sen(sentence,temperature=temperature)\n",
    "        return generate\n",
    "    \n",
    "    def predict_first(self, char,temperature =1):\n",
    "        '''根据给出的首个文字，生成五言绝句'''\n",
    "        if not self.model:\n",
    "            print('model not loaded')\n",
    "            return\n",
    "        \n",
    "        index = random.randint(0, self.poems_num)\n",
    "        #选取随机一首诗的最后max_len字符+给出的首个文字作为初始输入\n",
    "        sentence = self.poems[index][1-self.config.max_len:] + char\n",
    "        generate = str(char)\n",
    "        # print('first line = ',sentence)\n",
    "        # 直接预测后面23个字符\n",
    "        generate += self._preds(sentence,length=23,temperature=temperature)\n",
    "        return generate\n",
    "    \n",
    "    def predict_sen(self, text,temperature =1):\n",
    "        '''根据给出的前max_len个字，生成诗句'''\n",
    "        '''此例中，即根据给出的第一句诗句（含逗号），来生成古诗'''\n",
    "        if not self.model:\n",
    "            return\n",
    "        max_len = self.config.max_len\n",
    "        if len(text)<max_len:\n",
    "            print('length should not be less than ',max_len)\n",
    "            return\n",
    "\n",
    "        sentence = text[-max_len:]\n",
    "        print('the first line:',sentence)\n",
    "        generate = str(sentence)\n",
    "        generate += self._preds(sentence,length = 24-max_len,temperature=temperature)\n",
    "        return generate\n",
    "    \n",
    "    def predict_hide(self, text,temperature = 1):\n",
    "        '''根据给4个字，生成藏头诗五言绝句'''\n",
    "        if not self.model:\n",
    "            print('model not loaded')\n",
    "            return\n",
    "        if len(text)!=4:\n",
    "            print('藏头诗的输入必须是4个字！')\n",
    "            return\n",
    "        \n",
    "        index = random.randint(0, self.poems_num)\n",
    "        #选取随机一首诗的最后max_len字符+给出的首个文字作为初始输入\n",
    "        sentence = self.poems[index][1-self.config.max_len:] + text[0]\n",
    "        generate = str(text[0])\n",
    "        print('first line = ',sentence)\n",
    "        \n",
    "        for i in range(5):\n",
    "            next_char = self._pred(sentence,temperature)           \n",
    "            sentence = sentence[1:] + next_char\n",
    "            generate+= next_char\n",
    "        \n",
    "        for i in range(3):\n",
    "            generate += text[i+1]\n",
    "            sentence = sentence[1:] + text[i+1]\n",
    "            for i in range(5):\n",
    "                next_char = self._pred(sentence,temperature)           \n",
    "                sentence = sentence[1:] + next_char\n",
    "                generate+= next_char\n",
    "\n",
    "        return generate\n",
    "    \n",
    "    \n",
    "    def _preds(self,sentence,length = 23,temperature =1):\n",
    "        '''\n",
    "        sentence:预测输入值\n",
    "        lenth:预测出的字符串长度\n",
    "        供类内部调用，输入max_len长度字符串，返回length长度的预测值字符串\n",
    "        '''\n",
    "        sentence = sentence[:self.config.max_len]\n",
    "        generate = ''\n",
    "        for i in range(length):\n",
    "            pred = self._pred(sentence,temperature)\n",
    "            generate += pred\n",
    "            sentence = sentence[1:]+pred\n",
    "        return generate\n",
    "        \n",
    "        \n",
    "    def _pred(self,sentence,temperature =1):\n",
    "        '''内部使用方法，根据一串输入，返回单个预测字符'''\n",
    "        if len(sentence) < self.config.max_len:\n",
    "            print('in def _pred,length error ')\n",
    "            return\n",
    "        \n",
    "        sentence = sentence[-self.config.max_len:]\n",
    "        x_pred = np.zeros((1, self.config.max_len, len(self.words)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, self.word2numF(char)] = 1.\n",
    "        preds = self.model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = self.sample(preds,temperature=temperature)\n",
    "        next_char = self.num2word[next_index]\n",
    "        \n",
    "        return next_char\n",
    "\n",
    "    def data_generator(self):\n",
    "        '''生成器生成数据'''\n",
    "        i = 0\n",
    "        while 1:\n",
    "            x = self.files_content[i: i + self.config.max_len]\n",
    "            y = self.files_content[i + self.config.max_len]\n",
    "\n",
    "            if ']' in x or ']' in y:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            y_vec = np.zeros(\n",
    "                shape=(1, len(self.words)),\n",
    "                dtype=np.bool\n",
    "            )\n",
    "            y_vec[0, self.word2numF(y)] = 1.0\n",
    "\n",
    "            x_vec = np.zeros(\n",
    "                shape=(1, self.config.max_len, len(self.words)),\n",
    "                dtype=np.bool\n",
    "            )\n",
    "\n",
    "            for t, char in enumerate(x):\n",
    "                x_vec[0, t, self.word2numF(char)] = 1.0\n",
    "\n",
    "            yield x_vec, y_vec\n",
    "            i += 1\n",
    "\n",
    "    def train(self):\n",
    "        '''训练模型'''\n",
    "        print('training')\n",
    "        number_of_epoch = len(self.files_content)-(self.config.max_len + 1)*self.poems_num\n",
    "        number_of_epoch /= self.config.batch_size \n",
    "        number_of_epoch = int(number_of_epoch / 1.5)\n",
    "        print('epoches = ',number_of_epoch)\n",
    "        print('poems_num = ',self.poems_num)\n",
    "        print('len(self.files_content) = ',len(self.files_content))\n",
    "\n",
    "        if not self.model:\n",
    "            self.build_model()\n",
    "\n",
    "        self.model.fit_generator(\n",
    "            generator=self.data_generator(),\n",
    "            verbose=True,\n",
    "            steps_per_epoch=self.config.batch_size,\n",
    "            epochs=number_of_epoch,\n",
    "            callbacks=[\n",
    "                keras.callbacks.ModelCheckpoint(self.config.weight_file, save_weights_only=False),\n",
    "                LambdaCallback(on_epoch_end=self.generate_sample_result)\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    poetry_file = 'poetry.txt'\n",
    "    weight_file = 'poetry_model.h5'\n",
    "    # 根据前六个字预测第七个字\n",
    "    max_len = 6\n",
    "    batch_size = 32\n",
    "    learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PoetryModel(Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
