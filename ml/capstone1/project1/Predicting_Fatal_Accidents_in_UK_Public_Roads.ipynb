{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning in Python - Project 1.1 - 英国重大交通事故预测\n",
    "#### Topic and idea from: Achyut Kafle\n",
    "#### Data from: UK Department for Transport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简介 Introduction\n",
    "在英国，每年有数千人死于交通事故，同时有数十万人受到不同程度，甚至永久性的伤害。除了人员伤亡之外，道路交通事故还会造成时间、经济与心理损失，以及对非直接受害人造成的其他损失（比如说交通拥堵）。因此，了解导致交通事故的主要因素有助于政府制定政策以预防或减少事故，从而挽救与这些事故相关的损失。\n",
    "\n",
    "# 目的 Goal\n",
    "* 找到事故发生的决定性因素\n",
    "* 尝试根据已知环境预测交通事故的严重性\n",
    "\n",
    "# 数据 Data\n",
    "本次我们将使用 UK Department for Transport 提供的开源数据。这个数据集包括以下数据：\n",
    "* 时间和地点\n",
    "* 车祸中牵连的汽车数量\n",
    "* 道路与天气情况\n",
    "* 死亡人数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "!wget https://raw.githubusercontent.com/skyu0221/online-dropbox/master/ml/capstone1/project1/UK_RoadSafety_Accidents.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Features pre-processing and principal component analysis (pca) \n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Classifiers \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "\n",
    "# Classifiers ensembling\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "# Classifiers evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, auc, roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# Random resampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "\n",
    "# Tuning hyperparameters\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Other\n",
    "from time import time\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Ploting\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "from IPython.display import display\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "# Suppressing annoying harmless error\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    action=\"ignore\",\n",
    "    module=\"scipy\",\n",
    "    message=\"^internal gelsd\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "python_print = print\n",
    "\n",
    "def print(*objects, sep=' ', end='\\n', file=sys.stdout, color=(), fit_len=-1):\n",
    "    line = \"\".join(map(str, objects))\n",
    "    fit_len = max(fit_len - len(line), 0)\n",
    "    for c in color:\n",
    "        if len(objects) > 1:\n",
    "            objects = (f\"\\033[{c}m{objects[0]}\",) + objects[1:-1] + (\n",
    "                f\"{objects[-1]}{' ' * fit_len}\\033[0m\",)\n",
    "        elif len(objects) == 1:\n",
    "            objects = (f\"\\033[{c}m{objects[0]}{' ' * fit_len}\\033[0m\",)\n",
    "    python_print(*objects, sep=sep, end=end, file=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "df=pd.read_csv('UK_RoadSafety_Accidents.csv')\n",
    "\n",
    "# Print info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据清理 Data-cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find how many entry is missing in each feature\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSOA_of_Accident_Location stands for \"Lower Super Ouput Area of Accident_Location (England & Wales only)\", therefore not very useful\n",
    "df = df.drop(['LSOA_of_Accident_Location'], axis=1)\n",
    "df = df.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据检视 Data analysis\n",
    "\n",
    "#### 数据聚类 Data aggregation\n",
    "* \"Accident_Severity\": Fatal (1) / Serious (2) / Slight (3)\n",
    "\n",
    "    * -> \"Serious_Accident\": Serious/Fatal (1) vs. Slight (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Serious_Accident'] = 1\n",
    "df['Serious_Accident'][df['Accident_Severity'] == 3] = 0\n",
    "print('Count of outcome variable: \\n', df['Serious_Accident'].value_counts())\n",
    "\n",
    "# Count plot \n",
    "plt.figure(figsize=(9,6))\n",
    "ax = sns.countplot(x=df.Serious_Accident)\n",
    "for p in ax.patches:\n",
    "    x = p.get_bbox().get_points()[:,0]\n",
    "    y = p.get_bbox().get_points()[1,1]\n",
    "    ax.annotate('{:.1f}%'.format(100. * y / df['Serious_Accident'].value_counts().sum()), (x.mean(), y),\n",
    "                ha='center', va='bottom') # set the alignment of the text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据观察\n",
    "**Latitude & longitude**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split samples for plotting\n",
    "slight = df[df['Serious_Accident'] == 0]\n",
    "serious = df[df['Serious_Accident'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "# Latitude\n",
    "slight.Latitude.plot.density(label=\"Slight accidents\")\n",
    "serious.Latitude.plot.density(label=\"Fatal/serious accidents\")\n",
    "plt.legend()\n",
    "plt.title('Distribution plot: Latitude by the serverity of accidents')\n",
    "plt.xlim((49, 59))\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "# Longitude\n",
    "slight.Longitude.plot.density(label=\"Slight accidents\")\n",
    "serious.Longitude.plot.density(label=\"Fatal/serious accidents\")\n",
    "plt.legend()\n",
    "plt.title('Distribution plot: Longitude by the serverity of accidents')\n",
    "plt.xlim((-6, 2))\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of vehicles involved**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count and descriptive statistics\n",
    "print(\"Statistics about number of vehicles involved in each accident\", color=[93])\n",
    "print(df['Number_of_Vehicles'].describe())\n",
    "print()\n",
    "print(\"Number of accidents for different number of vehicles\", color=[92])\n",
    "count = df.groupby('Number_of_Vehicles')['Accident_Index'].count().to_frame()\n",
    "count[\"Percentage\"] = count / len(df) * 100\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To simplify the task, ignore accidents with more than 4 cars\n",
    "df = df.drop(df[df.Number_of_Vehicles > 4].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "ax = sns.countplot(x=df.Number_of_Vehicles, hue=df.Serious_Accident)\n",
    "for p in ax.patches:\n",
    "    x = p.get_bbox().get_points()[:,0]\n",
    "    y = p.get_bbox().get_points()[1,1]\n",
    "    ax.annotate('{:.1f}%'.format(100. * y / df['Serious_Accident'].value_counts().sum()), (x.mean(), y), \n",
    "                ha='center', va='bottom') # set the alignment of the text\n",
    "plt.xlabel(\"Number of vehicle involved\")\n",
    "plt.legend(labels=['Slight accidents', 'Serious/Fatal accidents'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of casualties**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count and descriptive statistics\n",
    "print(\"Statistics about number of casualties involved in each accident\", color=[93])\n",
    "print(df['Number_of_Casualties'].describe())\n",
    "print()\n",
    "print(\"Number of accidents for different number of casualties\", color=[92])\n",
    "count = df.groupby('Number_of_Casualties')['Accident_Index'].count().to_frame()\n",
    "count[\"Percentage\"] = count / len(df) * 100\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To simplify the task, ignore accidents with more than 4 casualties\n",
    "df = df.drop(df[df.Number_of_Casualties > 4].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "ax = sns.countplot(x=df.Number_of_Casualties, hue=df.Serious_Accident)\n",
    "for p in ax.patches:\n",
    "    x = p.get_bbox().get_points()[:,0]\n",
    "    y = p.get_bbox().get_points()[1,1]\n",
    "    ax.annotate('{:.1f}%'.format(100. * y / df['Serious_Accident'].value_counts().sum()), (x.mean(), y), \n",
    "            ha='center', va='bottom') # set the alignment of the text\n",
    "plt.xlabel(\"Number of casualties\")\n",
    "plt.legend(labels=['Slight accidents', 'Serious/Fatal accidents'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<center>========================= Categorical variables =========================</center>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-squared test of independence\n",
    "# https://en.wikipedia.org/wiki/Chi-squared_test\n",
    "def chi_sq_test(col1, col2):\n",
    "    count_table = pd.crosstab(df[col1], df[col2])\n",
    "    print(count_table)\n",
    "    print(stats.chisquare(count_table, axis=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Day of week**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day of week\n",
    "mapper = {1: \"Sunday\", 2: \"Monday\", 3: \"Tuesday\", 4: \"Wednesday\", 5: \"Thursday\", 6: \"Friday\", 7: \"Saturday\"}\n",
    "df['Day_of_Week'] = [mapper[i] for i in df['Day_of_Week']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "# Count plot  \n",
    "sns.countplot(x=df['Day_of_Week'], hue=\"Serious_Accident\", data=df, order=[mapper[i] for i in mapper])\n",
    "plt.xlabel('Day of week')\n",
    "plt.title('Count plot: Day of week and severity of accidents')\n",
    "plt.legend(labels=['Slight accidents', 'Serious/Fatal accidents'])\n",
    "plt.show()\n",
    "\n",
    "# Table of counts and chi-squared test of independence\n",
    "# p-value less than 0.05, reject null\n",
    "print('Chi-squared test of independence between days of week and severity of accidents', color=[91])\n",
    "print()\n",
    "chi_sq_test('Serious_Accident','Day_of_Week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Month of year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split date into month\n",
    "df['month'] = pd.DatetimeIndex(df['Date']).month\n",
    "\n",
    "# Month of year\n",
    "mapper = {1: \"JAN\", 2: \"FEB\", 3: \"MAR\", 4: \"APR\", 5: \"MAY\", 6: \"JUN\",\n",
    "          7: \"JUL\", 8: \"AUG\", 9: \"SEP\", 10: \"OCT\", 11: \"NOV\", 12: \"DEC\"}\n",
    "df['month'] = [mapper[i] for i in df['month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "# Count plot  \n",
    "sns.countplot(x=df['month'], hue=\"Serious_Accident\", data=df, order=[mapper[i] for i in mapper])\n",
    "plt.xlabel('Month of year')\n",
    "plt.title('Count plot: Month of year and severity of accidents')\n",
    "plt.legend(labels=['Slight accidents', 'Serious/Fatal accidents'])\n",
    "plt.show()\n",
    "\n",
    "# Table of counts and chi-squared test of independence\n",
    "print('Chi-squared test of independence between months of year and severity of accidents', color=[91])\n",
    "print()\n",
    "chi_sq_test('Serious_Accident','month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Day of month**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split day from date\n",
    "df['day'] = pd.DatetimeIndex(df['Date']).day\n",
    "\n",
    "# Day of month\n",
    "df['day'] = [f\"Day {i}\" for i in df['day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "# Count plot  \n",
    "sns.countplot(x=df['day'], hue=\"Serious_Accident\", data=df, order=[f\"Day {i + 1}\" for i in range(31)])\n",
    "plt.xlabel('Day of month')\n",
    "plt.xticks(rotation='45')\n",
    "plt.title('Count plot: Day of month and severity of accidents')\n",
    "plt.legend(labels=['Slight accidents', 'Serious/Fatal accidents'])\n",
    "plt.show()\n",
    "\n",
    "# Table of counts and chi-squared test of independence\n",
    "print('Chi-squared test of independence between days of month and severity of accidents', color=[91])\n",
    "print()\n",
    "chi_sq_test('Serious_Accident','day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hour of day**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hour of day\n",
    "df['hour'] = pd.DatetimeIndex(df['Time']).hour\n",
    "\n",
    "df['hour'] = [str(i) for i in df['hour']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "# Count plot\n",
    "sns.countplot(x=df['hour'], hue=\"Serious_Accident\", data=df, order=[str(i) for i in range(24)])\n",
    "plt.xlabel('Hour of day')\n",
    "plt.title('Count plot: Hour of day and severity of accidents')\n",
    "plt.legend(labels=['Slight accidents', 'Serious/Fatal accidents'])\n",
    "plt.show()\n",
    "\n",
    "# Table of counts and chi-squared test of independence\n",
    "print('Chi-squared test of independence between hours of day and severity of accidents', color=[91])\n",
    "print()\n",
    "chi_sq_test('Serious_Accident','hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First road class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Road class \n",
    "mapper = {1: \"Class A\", 2: \"Class A\", 3: \"Class A\", 4: \"Class B\", 5: \"Class C\"}\n",
    "df['1st_Road_Class'] = [mapper[i] if i in mapper else \"Unclassified\" for i in df['1st_Road_Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "# Count plot\n",
    "sns.countplot(x=df['1st_Road_Class'], hue=\"Serious_Accident\", data=df, order=[\"Class A\", \"Class B\", \"Class C\", \"Unclassified\"])\n",
    "plt.xlabel('Road class')\n",
    "plt.title('Count plot: Road class and severity of accidents')\n",
    "plt.legend(labels=['Slight accidents', 'Serious/Fatal accidents'])\n",
    "plt.show()\n",
    "\n",
    "# Table of counts and chi-squared test of independence\n",
    "print('Chi-squared test of independence between first road classes and severity of accidents', color=[91])\n",
    "print()\n",
    "chi_sq_test('Serious_Accident','1st_Road_Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Road type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing coded as -1\n",
    "df = df.drop(df[df.Road_Type == -1].index)\n",
    "\n",
    "# Road Type\n",
    "mapper = {3: \"Dual Carriage Way\", 6: \"Single Carriage Way\"}\n",
    "df['Road_Type'] = [mapper[i] if i in mapper else 'Road Type Other' for i in df['Road_Type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "# Count plot\n",
    "sns.countplot(x=df['Road_Type'], hue=\"Serious_Accident\", data=df)\n",
    "plt.xlabel('Road Type')\n",
    "plt.title('Count plot: Road type and severity of accidents')\n",
    "plt.legend(labels=['Slight accidents', 'Serious/Fatal accidents'])\n",
    "plt.show()\n",
    "\n",
    "# Table of counts and chi-squared test of independence\n",
    "print('Chi-squared test of independence between road types and severity of accidents', color=[91])\n",
    "print()\n",
    "chi_sq_test('Serious_Accident','Road_Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Speed limit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed limit\n",
    "df['Speed_limit'] = [f\"Limit {int(i)}\" for i in df['Speed_limit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "# Count plot\n",
    "sns.countplot(x=df['Speed_limit'], hue=\"Serious_Accident\", data=df)\n",
    "plt.xlabel('Speed limit')\n",
    "plt.title('Count plot: Speed limit and severity of accidents')\n",
    "plt.legend(labels=['Slight accidents', 'Serious/Fatal accidents'])\n",
    "plt.show()\n",
    "\n",
    "# Table of counts and chi-squared test of independence\n",
    "print('Chi-squared test of independence between road types and severity of accidents', color=[91])\n",
    "print()\n",
    "chi_sq_test('Serious_Accident','Speed_limit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Road junction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Road junction\n",
    "mapper = {0: \"Within 20m\", 1: \"Roundabout\", 2: \"Roundabout\", 3: \"T section\", 6: \"Crossroads\"}\n",
    "df['Junction_Detail'] = [mapper[i] if i in mapper else 'Other_Junction' for i in df['Junction_Detail']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "# Count plot\n",
    "sns.countplot(x=df['Junction_Detail'], hue=\"Serious_Accident\", data=df)\n",
    "plt.xlabel('Road junction')\n",
    "plt.title('Count plot: Road junctions and severity of accidents')\n",
    "plt.legend(labels=['Slight accidents', 'Serious/Fatal accidents'])\n",
    "plt.show()\n",
    "\n",
    "# Table of counts and chi-squared test of independence\n",
    "print('Chi-squared test of independence between road junctions and severity of accidents', color=[91])\n",
    "print()\n",
    "chi_sq_test('Serious_Accident','Junction_Detail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pedestrian crossing - physical facilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pedestrian_Crossing-Physical_Facilities\n",
    "mapper = {0: \"No Facility\", 5: \"Traffic Signal\"}\n",
    "df['PedCross_PhysFacs'] = [mapper[i] if i in mapper else 'Others' for i in df['Pedestrian_Crossing-Physical_Facilities']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "# Count plot\n",
    "sns.countplot(x=df['PedCross_PhysFacs'], hue=\"Serious_Accident\", data=df)\n",
    "plt.xlabel('Pedestrian crossing physical facilities')\n",
    "plt.title('Count plot: Pedestrian crossing physical facilities and severity of accidents')\n",
    "plt.legend(labels=['Slight accidents', 'Serious/Fatal accidents'])\n",
    "plt.show()\n",
    "\n",
    "# Table of counts and chi-squared test of independence\n",
    "print('Chi-squared test of independence between pedestrian physical crossing facilities and severity of accidents', color=[91])\n",
    "print()\n",
    "chi_sq_test('Serious_Accident','PedCross_PhysFacs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Light conditions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light conditions\n",
    "mapper = {1: \"Daylight\", 4: \"Dark - Light Lit\"}\n",
    "df['Light_Conditions'] = [mapper[i] if i in mapper else 'Other_LightConditions' for i in df['Light_Conditions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "# Count plot\n",
    "sns.countplot(x=df['Light_Conditions'], hue=\"Serious_Accident\", data=df)\n",
    "plt.xlabel('Light conditions')\n",
    "plt.title('Count plot: Light conditions and severity of accidents')\n",
    "plt.legend(labels=['Slight accidents', 'Serious/Fatal accidents'])\n",
    "plt.show()\n",
    "\n",
    "# Table of counts and chi-squared test of independence\n",
    "print('Chi-squared test of independence between road light conditions and severity of accidents', color=[91])\n",
    "print()\n",
    "chi_sq_test('Serious_Accident','Light_Conditions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Road surface conditions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing data coded as -1\n",
    "df = df.drop(df[df.Road_Surface_Conditions == -1].index)\n",
    "\n",
    "# Road conditions\n",
    "mapper = {1: \"Dry\", 2: \"Wet\", 5: \"Wet\"}\n",
    "df['Road_Surface_Conditions']=[mapper[i] if i in mapper else 'Other' for i in df['Road_Surface_Conditions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "# Count plot\n",
    "sns.countplot(x=df['Road_Surface_Conditions'], hue=\"Serious_Accident\", data=df)\n",
    "plt.xlabel('Road surface conditions')\n",
    "plt.title('Count plot: Light conditions and severity of accidents')\n",
    "plt.legend(labels=['Slight accidents', 'Serious/Fatal accidents'])\n",
    "plt.show()\n",
    "\n",
    "# Table of counts and chi-squared test of independence\n",
    "print('Chi-squared test of independence between road surface conditions and severity of accidents', color=[91])\n",
    "print()\n",
    "chi_sq_test('Serious_Accident','Road_Surface_Conditions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Urban rural classification of accident location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urban\n",
    "df[\"Urban\"] = [\"Urban\" if i == 1 else 'Rural' for i in df['Urban_or_Rural_Area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "# Count plot\n",
    "sns.countplot(x=df['Urban'], hue=\"Serious_Accident\", data=df)\n",
    "plt.xlabel('Urban rural classification')\n",
    "plt.title('Count plot: Rural/Urban and severity of accidents')\n",
    "plt.legend(labels=['Slight accidents', 'Serious/Fatal accidents'])\n",
    "plt.show()\n",
    "\n",
    "# Table of counts and chi-squared test of independence\n",
    "print('Chi-squared test of independence between rural/urban and severity of accidents', color=[91])\n",
    "print()\n",
    "chi_sq_test('Serious_Accident','Urban')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categirical variables into present/absent or dummy variables\n",
    "df = pd.get_dummies(df, columns=['Day_of_Week', 'month', 'day', 'hour', '1st_Road_Class', 'Road_Type', \n",
    "                                 'Speed_limit','Junction_Detail', 'PedCross_PhysFacs', 'Light_Conditions',\n",
    "                                 'Road_Surface_Conditions', 'Urban'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep relevant df features only\n",
    "df = df.drop(['Accident_Index','Location_Easting_OSGR', 'Location_Northing_OSGR', 'Police_Force', 'Accident_Severity',\n",
    "              'Date','Time','Local_Authority_(District)','Local_Authority_(Highway)','1st_Road_Number',\n",
    "              'Junction_Control', '2nd_Road_Class','2nd_Road_Number', 'Pedestrian_Crossing-Human_Control',\n",
    "              'Pedestrian_Crossing-Physical_Facilities','Special_Conditions_at_Site','Carriageway_Hazards',\n",
    "              'Urban_or_Rural_Area', 'Did_Police_Officer_Attend_Scene_of_Accident','Weather_Conditions'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "corrmat = df.corr()\n",
    "plt.subplots(figsize=(20,20))\n",
    "mask = np.zeros_like(corrmat, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(corrmat, mask=mask, vmax=0.9, cmap=\"YlGnBu\", square=True, cbar_kws={\"shrink\": .5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate label (y) and features (x)\n",
    "y = df.loc[:,'Serious_Accident']\n",
    "x = df.loc[:, df.columns != 'Serious_Accident']\n",
    "print('Shape of y: \\n', y.shape[0])\n",
    "print('Shape of x: \\n', x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 筛选"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal component analysis (PCA)\n",
    "Principal components analysis，(PCA）是一种统计分析、简化数据集的方法。它利用正交变换来对一系列可能相关的变量的观测值进行线性变换，从而投影为一系列线性不相关变量的值，这些不相关变量称为主成分（Principal Components）。具体地，主成分可以看做一个线性方程，其包含一系列线性系数来指示投影方向。PCA对原始数据的正则化或预处理敏感（相对缩放）。\n",
    "\n",
    "**基本思想**：\n",
    "+ 将坐标轴中心移到数据的中心，然后旋转坐标轴，使得数据在C1轴上的方差最大，即全部n个数据个体在该方向上的投影最为分散。意味着更多的信息被保留下来。C1成为第一主成分。\n",
    "+ C2第二主成分：找一个C2，使得C2与C1的协方差（相关系数）为0，以免与C1信息重叠，并且使数据在该方向的方差尽量最大。\n",
    "+ 以此类推，找到第三主成分，第四主成分。。。。第p个主成分。p个随机变量可以有p个主成分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the features\n",
    "x_stand = StandardScaler().fit_transform(x)\n",
    "\n",
    "# PCA to keep 95% of variance\n",
    "pca = PCA(0.95)\n",
    "\n",
    "# Components required to keep 95% of variance\n",
    "x_pca = pca.fit_transform(x_stand)\n",
    "\n",
    "# Cumulative sum of explained variance by the components\n",
    "var_cumsum = pca.explained_variance_ratio_.cumsum()\n",
    "print(\"Cumulative Sum of variance when increase number of components\", color=[91])\n",
    "print(var_cumsum)\n",
    "print()\n",
    "print(f'Need to keep {len(var_cumsum)} components to explain 95% of the variance.', color=[43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "pd.DataFrame(list(pca.explained_variance_ratio_)).plot()\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Variance explained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "\n",
    "* 根据 PCA 的结果，我们要保留 86 个 feature 才能 retain 95% variance。也就是说我们只能减少 20 个 feature（本来总共有 106 个 feature）。由于 86 个 feature 还是很多，所以我们用 K Best 来进一步缩小 feature 数量。\n",
    "* 我们会稍后用 K Best 的结果与用全部 feature 的结果进行比较"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select k best features\n",
    "k = 15\n",
    "x_kbest = x[x.columns[SelectKBest(f_classif, k=k).fit(x, y).get_support()]]\n",
    "print(\"K best features:\", color=[93])\n",
    "print(\"\\n\".join(list(x_kbest.columns)))\n",
    "print('Shape: ', x_kbest.shape, color=[91])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap with k best features\n",
    "df_kbest = pd.concat([y, x_kbest], axis=1)\n",
    "corrmat = df_kbest.corr()\n",
    "plt.subplots(figsize=(15,12))\n",
    "mask = np.zeros_like(corrmat, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(corrmat, annot=True, mask=mask, vmax=0.9, cmap=\"YlGnBu\", square=True, cbar_kws={\"shrink\": .5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final samples\n",
    "print('Number of samples: ', df.shape[0], color=[43])\n",
    "print('Proportion of positive outcomes: ', round(df['Serious_Accident'].mean(), 2), color=[43])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "\n",
    "* 由于 positive outcome 只有 17%，所以我们的 sample 是 imbalance 的。我们需要将 sample 调整成 50/50。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split samples into train (80%) and test (20%) samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_kbest, y, test_size=0.2, random_state=321)\n",
    "print('Train samples: ', X_train.shape)\n",
    "print('Test samples: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random under sampling of majority class\n",
    "rus = RandomUnderSampler(random_state=321)\n",
    "\n",
    "X_train_rus, y_train_rus = rus.fit_sample(X_train, y_train)\n",
    "idx = rus.sample_indices_\n",
    "print('Random under sampling', Counter(y_train_rus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to fit, predict and then print outputs\n",
    "def fit_eval_clf(model):\n",
    "    start = time()\n",
    "    #Fit the model in train samples\n",
    "    prediction = model.fit(X_train_rus, y_train_rus).predict(X_test)\n",
    "    \n",
    "    # Cross-validated accuracy score\n",
    "    accu_train = cross_val_score(model, X_train_rus, y_train_rus, cv=10, scoring='accuracy')\n",
    "    print(f\"Cross-validated accuracy score on train samples: {accu_train.mean():.3} (+/-{accu_train.std() * 2:.3})\")\n",
    "    \n",
    "    # Cros-validated area under ROC curve \n",
    "    au_roc_train = cross_val_score(model, X_train_rus, y_train_rus, cv=10, scoring='roc_auc')\n",
    "    print (f\"Cross-validated area under ROC curve on train samples: {au_roc_train.mean()} (+/- {au_roc_train.std() * 2})\")\n",
    "    print('\\n')\n",
    "\n",
    "    # Accuracy score on test samples\n",
    "    print (f\"Accuracy score on test samples: \", round(accuracy_score(y_test, prediction), 4))\n",
    "    \n",
    "    # Area under ROC on test samples\n",
    "    print (f\"Area under ROC curve on test samples: \", round(roc_auc_score(y_test, prediction), 4))\n",
    "    print()\n",
    "    print(f\"Total time to run: {(time() - start) / 60:.2} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_search_cv(model, params):\n",
    "    start = time()\n",
    "    # Tune the hyperparameters via a randomized search\n",
    "    rgrid = RandomizedSearchCV(model, params, random_state=321, scoring='roc_auc')\n",
    "    rgrid.fit(X_train_rus, y_train_rus)\n",
    "    print(f\"Randomized search took {(time() - start) / 60} minutes.\")\n",
    "    print('Best hyperparameters: ', rgrid.best_params_)\n",
    "    return rgrid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers: Baseline performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KNN Classifier: Baseline performance\\n')\n",
    "fit_eval_clf(KNeighborsClassifier(n_jobs=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Support Vector: Baseline performance\\n')\n",
    "fit_eval_clf(SVC(random_state=321))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Logistic Regression: Baseline performance\\n')\n",
    "fit_eval_clf(LogisticRegression(random_state=321))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Forest: Baseline performance\\n')\n",
    "fit_eval_clf(RandomForestClassifier(n_jobs=-1,random_state=321))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers: Tune hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune K-Nearest Neighbors (KNN) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the set of hyperparameters to tune\n",
    "params = {'n_neighbors':[5,6,7],\n",
    "          'leaf_size':[1,2,3],\n",
    "          'weights':['uniform', 'distance'],\n",
    "          'algorithm':['auto', 'ball_tree','kd_tree']}\n",
    "best_knn = rand_search_cv(KNeighborsClassifier(), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KNN Classifier: Performance after tuning hyperparameters\\n')\n",
    "fit_eval_clf(KNeighborsClassifier(**best_knn, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Support Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the set of hyperparameters to tune\n",
    "params = {'C': [0.01,0.1,1,3], \n",
    "          'gamma': [0.01, 0.1, 1]}\n",
    "best_sv = rand_search_cv(SVC(), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Support Vector: Performance after tuning hyperparameters\\n')\n",
    "fit_eval_clf(SVC(**best_sv, random_state=321))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the set of hyperparameters to tune\n",
    "params = {'C': [0.01, 0.1, 1, 5, 10],\n",
    "          'penalty':['l2']}\n",
    "best_lr = rand_search_cv(LogisticRegression(random_state=321), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Logistic Regression: Performance after tuning hyperparameters\\n')\n",
    "fit_eval_clf(LogisticRegression(**best_lr, random_state=321))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the set of hyperparameters to tune\n",
    "params = {'max_depth': [ 10, 15, 20, 30, 40],\n",
    "          'min_samples_leaf': [1, 3, 4, 7],\n",
    "          'min_samples_split': [2, 5, 7, 9],\n",
    "          'n_estimators': [100, 200, 500, 700]}\n",
    "best_rf = rand_search_cv(RandomForestClassifier(), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Forest: Performance after tuning hyperparameters \\n')\n",
    "fit_eval_clf(RandomForestClassifier(**best_rf, n_jobs=-1, random_state=321))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances\n",
    "model = RandomForestClassifier(**best_rf, n_jobs=-1, random_state=321)\n",
    "model.fit(X_train_rus,y_train_rus)\n",
    "\n",
    "feat_imp = pd.Series(model.feature_importances_, index=x_kbest.columns).sort_values(ascending=False)\n",
    "\n",
    "# Set figure size\n",
    "fig = plt.figure(figsize=(12,9))\n",
    "ax = fig.gca()\n",
    "\n",
    "feat_imp.plot(kind='bar', title='Tuned Random Forest: Feature Importances', ax=ax)\n",
    "plt.ylabel('Feature Importance Score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "\n",
    "# Tuned Classifiers\n",
    "knn = KNeighborsClassifier(**best_knn,n_jobs=-1)\n",
    "svc = SVC(**best_sv, probability=True)\n",
    "logit = LogisticRegression(**best_lr, random_state=321)\n",
    "rfc = RandomForestClassifier(**best_rf, n_jobs=-1, random_state=321)\n",
    "\n",
    "# Create the ensemble model\n",
    "voting_clf = VotingClassifier(estimators=[('KNN', knn), ('Support Vector', svc),('Logistic Regression', logit),\n",
    "                                          ('Random Forest', rfc)], voting='soft', weights=[1,2,2,2])\n",
    "\n",
    "#Fit the model \n",
    "prediction=voting_clf.fit(X_train_rus, y_train_rus).predict(X_test)\n",
    "\n",
    "# Accuracy score on test samples\n",
    "print (\"Accuracy score on test samples: \", round(accuracy_score (y_test, prediction), 4))\n",
    "    \n",
    "# Area under ROC on test samples\n",
    "print (\"Area under ROC curve on test samples: \", round(roc_auc_score (y_test, prediction), 4))\n",
    "print()\n",
    "print(f\"Total time to run: {(time() - start) / 60:.2} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting method 1: Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gradient boosting classifier\\n')\n",
    "fit_eval_clf(GradientBoostingClassifier(random_state=321))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting method 2: Adaptive boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Adaptive boosting classifier\\n')\n",
    "fit_eval_clf(AdaBoostClassifier(random_state=321))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Stacking classifier\\n')\n",
    "start=time()\n",
    "\n",
    "# Stacking Classifier\n",
    "stacked_clf = StackingClassifier(classifiers=[knn, svc, rfc], meta_classifier=logit)\n",
    "\n",
    "#Fit the model \n",
    "prediction=stacked_clf.fit(X_train_rus, y_train_rus).predict(X_test)\n",
    "\n",
    "# Accuracy score on test samples\n",
    "print (\"Accuracy score on test samples: \", round(accuracy_score (y_test, prediction), 4))\n",
    "    \n",
    "# Area under ROC on test samples\n",
    "print (\"Area under ROC curve on test samples: \", round(roc_auc_score (y_test, prediction), 4))\n",
    "print()\n",
    "print(f\"Total time to run: {(time() - start) / 60:.2} minutes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performances of baseline and tuned classifiers\n",
    "clf_perform = pd.DataFrame({'Classifier': ['KNN', 'Support Vector', 'Logistic Regression', 'Random Forest'],\n",
    "                            'Accuracy_Baseline': [0.5667, 0.6245, 0.6046, 0.5994],\n",
    "                            'Accuracy_Tuned': [0.5743, 0.6238, 0.6051, 0.6389],\n",
    "                            'AreaunderROC_Baseline': [0.5694, 0.6068, 0.5986, 0.5652], \n",
    "                            'AreaunderROC_Tuned': [0.5748, 0.6085, 0.5998, 0.6115]})\n",
    "# Set figure size\n",
    "fig = plt.figure(figsize = (10,8))\n",
    "ax = fig.gca()\n",
    "\n",
    "clf_perform.plot(kind='bar', x='Classifier', title='Classifier performance', ylim=[0.4,0.7], ax=ax)\n",
    "plt.xticks(rotation=35)\n",
    "plt.ylabel('Score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performances of ensemble classifiers\n",
    "ensemble_perform = pd.DataFrame({'Ensemble': ['Bagging_Voting', 'Gradient boosting', 'Adaptive boosting', \n",
    "                                              'Stacking_Classifier'],\n",
    "                                 'Accuracy': [0.6221, 0.6357, 0.6285, 0.5743],\n",
    "                                 'Areaunder_ROC': [0.6105, 0.6144, 0.6107, 0.5748]})\n",
    "# Set figure size\n",
    "fig = plt.figure(figsize = (10,8))\n",
    "ax = fig.gca()\n",
    "\n",
    "ensemble_perform.plot(x='Ensemble',kind='bar',ylim=[0.4,0.7], title='Ensemble Classifiers Performance', ax=ax)\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=23)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf_perform)\n",
    "print(ensemble_perform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "* 最重要的 feature 是 Number of vehicles involved, location (latitude and longitude), speed limit (60mph), urban location and number of casualties"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
